{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMLfXpbyQ+sbAkw5ar1QOD6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"93483c8237be4e1a9c9b449ca0bc424b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6fdbf8f373749638bd52e5bb58816bb","IPY_MODEL_c66f7dbb40f84651bc74f504559b5c07","IPY_MODEL_24e0f6944a0a4ce3bf48cb842ae0d82d"],"layout":"IPY_MODEL_90e5b957aede4237bd4111adc1b619ca"}},"d6fdbf8f373749638bd52e5bb58816bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d90166e7bb448eb206abe136659129","placeholder":"​","style":"IPY_MODEL_3afe41c5b63a4910a83a1afc49aaaf36","value":"Map: 100%"}},"c66f7dbb40f84651bc74f504559b5c07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba3354ea21c0410fb00ca894e01bd194","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bfb9b5b466d46b1888c6759f8659cf6","value":157}},"24e0f6944a0a4ce3bf48cb842ae0d82d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9f03723ce414354a1d303aed17c6c69","placeholder":"​","style":"IPY_MODEL_c67e8babb309411ea9a1f2dfa03294f1","value":" 157/157 [00:00&lt;00:00, 1216.65 examples/s]"}},"90e5b957aede4237bd4111adc1b619ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9d90166e7bb448eb206abe136659129":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3afe41c5b63a4910a83a1afc49aaaf36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba3354ea21c0410fb00ca894e01bd194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bfb9b5b466d46b1888c6759f8659cf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9f03723ce414354a1d303aed17c6c69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c67e8babb309411ea9a1f2dfa03294f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#@title mount to drive (ドライブにマウント)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iCsyzu6G9dx","executionInfo":{"status":"ok","timestamp":1707532176175,"user_tz":-540,"elapsed":18411,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"outputId":"f07251fe-f745-4b21-e4d9-7c05bec44fcb","cellView":"form"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Tesla T4, 15360 MiB, 15101 MiB\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"t9RS7jcZGoEl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707532211721,"user_tz":-540,"elapsed":32411,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"outputId":"2f07f9da-d494-4dee-8dae-112b46d6f0d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/244.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/244.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}],"source":["# パッケージのインストール\n","!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n","!pip install sentencepiece"]},{"cell_type":"code","source":["# パッケージのインポート\n","import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, PeftModel\n","from trl import SFTTrainer"],"metadata":{"id":"E7DmkY2HG-Xj","executionInfo":{"status":"ok","timestamp":1707532255591,"user_tz":-540,"elapsed":22711,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#@title Read dataset (データセットを読む)\n","\n","#@markdown json_name\n","dataset_json_name = \"mafuyu.json\" #@param{type:\"string\"}\n","\n","#@markdown result_name\n","result_name = \"mafuyu\" #@param{type:\"string\"}\n","\n","\n","import json\n","import os\n","from datasets import load_dataset, load_metric, Dataset\n","\n","\n","\n","# 仮定: dataは指定されたJSONデータを含む\n","with open(os.path.join(\"/content/drive/MyDrive/Rinna\",dataset_json_name),encoding = \"utf-8\") as f:\n","   yaoyao_data = json.load(f)\n","\n","# text列を追加する関数\n","def add_text(entry):\n","    entry[\"text\"] = f\"\"\"指示:\n","{entry[\"instruction\"]}\n","\n","応答:\n","{entry[\"output\"]}\"\"\"\n","    return entry\n","\n","# 各エントリに対してtext列を追加\n","updated_data = [add_text(entry) for entry in yaoyao_data]\n","\n","text_data = [{\"text\": entry[\"text\"]} for entry in updated_data]\n","\n","# 新しいデータをDatasetオブジェクトに変換\n","dataset = Dataset.from_dict({\"text\": [entry[\"text\"] for entry in text_data]})"],"metadata":{"id":"fPWtLdJWWzfW","executionInfo":{"status":"ok","timestamp":1707532263793,"user_tz":-540,"elapsed":646,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(dataset)\n","print(dataset[1][\"text\"])"],"metadata":{"id":"-xAZh6R4Viyu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707533049908,"user_tz":-540,"elapsed":251,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"outputId":"9301bb18-7e3c-4c09-f753-39b6ee185649"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text'],\n","    num_rows: 157\n","})\n","指示:\n","まふゆは、どう思った？\n","\n","応答:\n","・・・暖かくて、いいと思った...\n"]}]},{"cell_type":"code","source":["# 量子化パラメータ\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,  # 4bitベースモデルの有効化\n","    bnb_4bit_quant_type=\"nf4\",  # 量子化種別 (fp4 or nf4)\n","    bnb_4bit_compute_dtype=torch.float16,  # 4bitベースモデルのdtype (float16 or bfloat16)\n","    bnb_4bit_use_double_quant=False,  # 4bitベースモデルのネストされた量子化の有効化 (二重量子化)\n",")\n","\n","# モデルの準備\n","model_name = \"rinna/japanese-gpt-neox-3.6b-instruction-sft\"\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,  # モデル名\n","    quantization_config=bnb_config,  # 量子化パラメータ\n","    device_map={\"\": 0}  # モデル全体をGPU0にロード\n",")\n","model.config.use_cache = False  # キャッシュ (学習時はFalse)\n","\n","tokenizer = AutoTokenizer.from_pretrained(\n","    model_name,  # モデル名\n","    use_fast=False,  # Fastトークナイザーの有効化\n","    add_eos_token=True,  # データへのEOSの追加を指示\n","    trust_remote_code=True\n",")"],"metadata":{"id":"3B6wIobsHPSA","executionInfo":{"status":"ok","timestamp":1707533082576,"user_tz":-540,"elapsed":32372,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#@title Train (学習)\n","# LoRAパラメータ\n","peft_config = LoraConfig(\n","    r=64,  # LoRAアテンションの次元\n","    lora_alpha=16,  # LoRAスケーリングのAlphaパラメータ\n","    lora_dropout=0.1,  # LoRA レイヤーのドロップアウト確率\n","    bias=\"none\",  # LoRAのバイアス種別 (\"none\",\"all\", \"lora_only\")\n","    task_type=\"CAUSAL_LM\",  # タスク種別\n","    target_modules=[\"dense_4h_to_h\", \"dense\", \"dense_h_to_4h\", \"query_key_value\"]\n",")\n","\n","\n","out_dir = \"./result_\"+str(result_name)\n","# 学習パラメータ\n","training_arguments = TrainingArguments(\n","    output_dir=out_dir,  # 出力ディレクトリ\n","    fp16=True,  # fp16学習の有効化 (T4:True,A100:False)\n","    bf16=False,  # bf16学習の有効化 (T4:False,A100:True)\n","    max_steps=800,  # 学習ステップ数\n","    per_device_train_batch_size=8,  # 学習用のGPUあたりのバッチサイズ\n","    gradient_accumulation_steps=1,  # 勾配を蓄積するための更新ステップの数\n","    optim=\"paged_adamw_32bit\",  # オプティマイザ\n","    learning_rate=2e-4,  # 初期学習率 (AdamW オプティマイザー)\n","    lr_scheduler_type=\"cosine\",  # 学習率スケジュール\n","    max_grad_norm=0.3,  # 最大法線勾配 (勾配クリッピング)\n","    warmup_ratio=0.03,  # 線形ウォームアップのステップ比率 (0から学習率まで)\n","    weight_decay=0.001,  # bias/LayerNormウェイトを除く全レイヤーに適用するウェイト減衰\n","    save_steps=0,  # 何ステップ毎にチェックポイントを保存するか\n","    logging_steps=25,  # 何ステップ毎にログを記録するか\n","    group_by_length=True,  # シーケンスを同じ長さのバッチにグループ化 (メモリ節約して学習速度が大幅アップ)\n","    report_to=\"tensorboard\"  # レポート\n",")\n","\n","# SFTパラメータ\n","trainer = SFTTrainer(\n","    model=model,  # モデル\n","    tokenizer=tokenizer,  # トークナイザー\n","    train_dataset=dataset,  # データセット\n","    dataset_text_field=\"text\",  # データセットのtext列\n","    peft_config=peft_config,  # PEFTパラメータ\n","    args=training_arguments,  # 学習パラメータ\n",")\n","\n","# モデルの学習\n","trainer.train()\n","trainer.model.save_pretrained(os.path.join(\"/content/drive/MyDrive/Rinna\",out_dir))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["93483c8237be4e1a9c9b449ca0bc424b","d6fdbf8f373749638bd52e5bb58816bb","c66f7dbb40f84651bc74f504559b5c07","24e0f6944a0a4ce3bf48cb842ae0d82d","90e5b957aede4237bd4111adc1b619ca","b9d90166e7bb448eb206abe136659129","3afe41c5b63a4910a83a1afc49aaaf36","ba3354ea21c0410fb00ca894e01bd194","7bfb9b5b466d46b1888c6759f8659cf6","b9f03723ce414354a1d303aed17c6c69","c67e8babb309411ea9a1f2dfa03294f1"]},"id":"7yzaiUMZHTJc","executionInfo":{"status":"ok","timestamp":1707534115960,"user_tz":-540,"elapsed":1033387,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"outputId":"549dc4ad-a8d1-4464-ffbf-030f4dc68567"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/157 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93483c8237be4e1a9c9b449ca0bc424b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [800/800 16:35, Epoch 40/40]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>3.603700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.390700</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.761400</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.973700</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.463800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.300600</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.246300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.225600</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>0.205600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.202400</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>0.193500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.192700</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>0.174700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.175000</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>0.172900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.177300</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>0.163600</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.163400</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>0.165900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.169800</td>\n","    </tr>\n","    <tr>\n","      <td>525</td>\n","      <td>0.154800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.158700</td>\n","    </tr>\n","    <tr>\n","      <td>575</td>\n","      <td>0.161100</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.161100</td>\n","    </tr>\n","    <tr>\n","      <td>625</td>\n","      <td>0.152000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.153700</td>\n","    </tr>\n","    <tr>\n","      <td>675</td>\n","      <td>0.155100</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.160600</td>\n","    </tr>\n","    <tr>\n","      <td>725</td>\n","      <td>0.149200</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.154700</td>\n","    </tr>\n","    <tr>\n","      <td>775</td>\n","      <td>0.155700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.152400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["#@title 学習終わりの推論\n","\n","#@markdown json_name\n","prompt = \"\\u8CB4\\u65B9\\u306E\\u540D\\u524D\\u306F\\uFF1F\" #@param{type:\"string\"}\n","\n","\n","final_prompt = f\"\"\"指示:{prompt}\n","\n","応答:\n","\"\"\"\n","\n","# 推論の実行\n","input_ids = tokenizer.encode(final_prompt, add_special_tokens=False, return_tensors=\"pt\")\n","output_ids = model.generate(\n","    input_ids.to(device=model.device),\n","    max_length=200,\n","    temperature=0.7,\n","    do_sample=True,\n",")\n","output = tokenizer.decode(output_ids.tolist()[0][input_ids.size(1):])\n","\n","print(\"\")\n","print(prompt)\n","print(output)"],"metadata":{"id":"zNDIpLcnZ2hy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707534117178,"user_tz":-540,"elapsed":1222,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"outputId":"989b472b-1803-42d7-d95f-72cb1e23b727"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n","  warnings.warn(\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","貴方の名前は？\n","・・・朝比奈まふゆ</s>\n"]}]},{"cell_type":"code","source":["#@title 推論のみ\n","# モデルの準備\n","import os\n","model_name = \"rinna/japanese-gpt-neox-3.6b-instruction-sft\"\n","\n","out_dir = \"./result_\"+str(result_name)\n","print(out_dir)\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,  # 4bitベースモデルの有効化\n","    bnb_4bit_quant_type=\"nf4\",  # 量子化種別 (fp4 or nf4)\n","    bnb_4bit_compute_dtype=torch.float16,  # 4bitベースモデルのdtype (float16 or bfloat16)\n","    bnb_4bit_use_double_quant=False,  # 4bitベースモデルのネストされた量子化の有効化 (二重量子化)\n",")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map={\"\": 0}\n",")\n","model = PeftModel.from_pretrained(\n","    base_model,\n","    os.path.join(\"/content/drive/MyDrive/Rinna\",out_dir)\n",")\n","\n","# トークナイザーの準備\n","tokenizer = AutoTokenizer.from_pretrained(\n","    model_name,\n","    use_fast=False,\n","    add_eos_token=True,\n","    trust_remote_code=True\n",")"],"metadata":{"id":"f5qnD0PmaFd-","executionInfo":{"status":"ok","timestamp":1707534185297,"user_tz":-540,"elapsed":68122,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e25905ea-e91e-4967-cd84-b93955dcb63a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["./result_mafuyu\n"]}]},{"cell_type":"code","source":["# プロンプトの準備\n","\n","#@markdown json_name\n","prompt = \"\\u8CB4\\u65B9\\u306E\\u540D\\u524D\\u306F\\uFF1F\" #@param{type:\"string\"}\n","\n","\n","final_prompt = f\"\"\"指示:\\n{prompt}\n","\n","応答:\n","\"\"\"\n","\n","# 推論の実行\n","input_ids = tokenizer.encode(final_prompt, add_special_tokens=False, return_tensors=\"pt\")\n","output_ids = model.generate(\n","    input_ids=input_ids.to(device=model.device),\n","    max_length=200,\n","    temperature=0.7,\n","    do_sample=True,\n",")\n","output = tokenizer.decode(output_ids.tolist()[0][input_ids.size(1):])\n","\n","print(\"\")\n","print(prompt)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deGCBN8Bb2Km","executionInfo":{"status":"ok","timestamp":1707534186336,"user_tz":-540,"elapsed":1042,"user":{"displayName":"teftef teftef","userId":"07416888417699909768"}},"outputId":"897b1dcc-5ef3-48a3-d3d1-769a18bbf566"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["\n","貴方の名前は？\n","・・・朝比奈まふゆ</s>\n"]}]}]}